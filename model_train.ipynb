{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasrivastava/miniconda3/envs/whisper/lib/python3.10/site-packages/resemblyzer/voice_encoder.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Loaded 27 files from ./devesh\n",
      "Loaded the voice encoder model on cpu in 0.00 seconds.\n",
      "Loaded 26 files from ./rakshit\n",
      "Loaded the voice encoder model on cpu in 0.00 seconds.\n",
      "Loaded 11 files from ./not_devesh\n",
      "Total samples: 64\n",
      "Number of Devesh samples: 27\n",
      "Number of Rakshit samples: 26\n",
      "Number of Other samples: 11\n",
      "\n",
      "Test set evaluation:\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Devesh       0.75      1.00      0.86         6\n",
      "     Rakshit       1.00      0.60      0.75         5\n",
      "      Others       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.92      0.87      0.87        13\n",
      "weighted avg       0.88      0.85      0.84        13\n",
      "\n",
      "\n",
      "Cross-validation results:\n",
      "CV scores: [1.         0.92307692 0.84615385 1.         1.        ]\n",
      "Mean CV accuracy: 0.95 (+/- 0.12)\n",
      "Model saved to ./speaker_classifier_model.pkl\n",
      "Model loaded from ./speaker_classifier_model.pkl\n",
      "Audio file not found: test.mp3\n"
     ]
    }
   ],
   "source": [
    "### model training\n",
    "\n",
    "import os\n",
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBClassifier  # Add this import\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Replace these with your actual folder paths\n",
    "devesh_folder = \"./devesh\"\n",
    "rakshit_folder = \"./rakshit\"\n",
    "others_folder = \"./not_devesh\"\n",
    "\n",
    "def load_audio_files(folder_path, label):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    encoder = VoiceEncoder()\n",
    "    \n",
    "    files_count = 0\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mp3') or file_name.endswith('.wav'):\n",
    "            files_count += 1\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            wav = preprocess_wav(file_path)\n",
    "            embed = encoder.embed_utterance(wav)\n",
    "            embeddings.append(embed)\n",
    "            labels.append(label)\n",
    "    \n",
    "    print(f\"Loaded {files_count} files from {folder_path}\")\n",
    "    return embeddings, labels\n",
    "\n",
    "# Load all three classes of audio files\n",
    "devesh_embeddings, devesh_labels = load_audio_files(devesh_folder, label=0)\n",
    "rakshit_embeddings, rakshit_labels = load_audio_files(rakshit_folder, label=1)\n",
    "others_embeddings, others_labels = load_audio_files(others_folder, label=2)\n",
    "\n",
    "# Combine all data\n",
    "X = np.vstack((devesh_embeddings, rakshit_embeddings, others_embeddings))\n",
    "y = np.hstack((devesh_labels, rakshit_labels, others_labels))\n",
    "n_components = 8  # You can adjust this number\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X=X_reduced\n",
    "# Train the classifier\n",
    "# Add validation checks before training\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of Devesh samples: {sum(y == 0)}\")\n",
    "print(f\"Number of Rakshit samples: {sum(y == 1)}\")\n",
    "print(f\"Number of Other samples: {sum(y == 2)}\")\n",
    "\n",
    "if len(X) < 30:  # Increased threshold for 3 classes\n",
    "    print(\"Warning: Very small dataset. Results may not be reliable.\")\n",
    "\n",
    "if sum(y == 0) < 5 or sum(y == 1) < 5 or sum(y == 2) < 5:  # Check all three classes\n",
    "    print(\"Warning: One or more classes have very few samples.\")\n",
    "\n",
    "# Split data into train/test sets first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_pred = clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "print(\"\\nTest set evaluation:\")\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_pred, target_names=['Devesh', 'Rakshit', 'Others']))\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"CV scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n",
    "\n",
    "# Check for perfect separation\n",
    "if cv_scores.mean() > 0.99:\n",
    "    print(\"\\nWarning: Near-perfect accuracy detected. This might indicate:\")\n",
    "    print(\"1. Data leakage\")\n",
    "    print(\"2. Duplicate or very similar samples across folders\")\n",
    "    print(\"3. Insufficient data diversity\")\n",
    "    print(\"4. Insufficient inter-class variation\")\n",
    "    print(\"Please verify your dataset and data splitting process.\")\n",
    "\n",
    "### model saving\n",
    "\n",
    "import joblib\n",
    "\n",
    "model_path = \"./speaker_classifier_model.pkl\"\n",
    "joblib.dump(clf, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "### model inference\n",
    "\n",
    "import os\n",
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"./speaker_classifier_model.pkl\"\n",
    "clf = joblib.load(model_path)\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "def predict_speaker(audio_file_path):\n",
    "    \"\"\"\n",
    "    Predict if the speaker in the audio file is Devesh (0), Rakshit (1), or Other (2).\n",
    "\n",
    "    Parameters:\n",
    "        audio_file_path (str): Path to the audio file to predict.\n",
    "    \n",
    "    Returns:\n",
    "        int: 0 if Devesh, 1 if Rakshit, 2 if Other\n",
    "    \"\"\"\n",
    "    # Load and preprocess the audio\n",
    "    encoder = VoiceEncoder()\n",
    "    wav = preprocess_wav(audio_file_path)\n",
    "    embed = encoder.embed_utterance(wav)\n",
    "    \n",
    "    # Reshape the embedding to match the model's expected input shape\n",
    "    embed = embed.reshape(1, -1)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = clf.predict(embed)[0]\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "audio_file_path = \"test.mp3\"  # Replace with the actual test audio file path\n",
    "\n",
    "if os.path.exists(audio_file_path):\n",
    "    prediction = predict_speaker(audio_file_path)\n",
    "    speaker = \"Devesh\" if prediction == 0 else \"Rakshit\" if prediction == 1 else \"Other\"\n",
    "    print(f\"The speaker in the audio file is: {speaker}\")\n",
    "else:\n",
    "    print(f\"Audio file not found: {audio_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding dimensions:\n",
      "Single embedding shape: (256,)\n",
      "Full X matrix shape: (64, 8)\n",
      "Full y vector shape: (64,)\n",
      "\n",
      "Data validation:\n",
      "Any NaN values in X: False\n",
      "Any infinite values in X: False\n"
     ]
    }
   ],
   "source": [
    "# Add this after creating embeddings but before training\n",
    "print(\"\\nEmbedding dimensions:\")\n",
    "print(f\"Single embedding shape: {devesh_embeddings[0].shape}\")\n",
    "print(f\"Full X matrix shape: {X.shape}\")\n",
    "print(f\"Full y vector shape: {y.shape}\")\n",
    "\n",
    "# Optional: Check for any NaN values\n",
    "print(\"\\nData validation:\")\n",
    "print(f\"Any NaN values in X: {np.isnan(X).any()}\")\n",
    "print(f\"Any infinite values in X: {np.isinf(X).any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./speaker_classifier_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "import joblib  # Add this line to import joblib\n",
    "\n",
    "model_path = \"./speaker_classifier_model.pkl\"\n",
    "joblib.dump(clf, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./speaker_classifier_model.pkl\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "The speaker in the audio file is: Devesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasrivastava/miniconda3/envs/whisper/lib/python3.10/site-packages/resemblyzer/voice_encoder.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"./speaker_classifier_model.pkl\"\n",
    "clf = joblib.load(model_path)\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "# Function to load and process a single audio file for inference\n",
    "def predict_speaker(audio_file_path):\n",
    "    \"\"\"\n",
    "    Predict if the speaker in the audio file is Devesh (1) or not (0).\n",
    "\n",
    "    Parameters:\n",
    "        audio_file_path (str): Path to the audio file to predict.\n",
    "    \n",
    "    Returns:\n",
    "        int: 1 if the speaker is Devesh, 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the audio\n",
    "    encoder = VoiceEncoder()\n",
    "    wav = preprocess_wav(audio_file_path)\n",
    "    embed = encoder.embed_utterance(wav)\n",
    "    \n",
    "    # Reshape the embedding to match the model's expected input shape\n",
    "    embed = embed.reshape(1, -1)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = clf.predict(embed)[0]\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "audio_file_path = \"devesh_test.mp3\"  # Replace with the actual test audio file path\n",
    "\n",
    "if os.path.exists(audio_file_path):\n",
    "    prediction = predict_speaker(audio_file_path)\n",
    "    speaker = \"Devesh\" if prediction == 1 else \"Not Devesh\"\n",
    "    print(f\"The speaker in the audio file is: {speaker}\")\n",
    "else:\n",
    "    print(f\"Audio file not found: {audio_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
